{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fetSbKRrczhD"
   },
   "source": [
    "Copyright 2020 DeepMind Technologies Limited.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "HaswJZMq9B3c",
    "tags": []
   },
   "source": [
    "# @title Download Model {form-width: \"25%\"}\n",
    "\n",
    "%mkdir tapnet/checkpoints\n",
    "\n",
    "!wget -P tapnet/checkpoints https://storage.googleapis.com/dm-tapnet/tapir_checkpoint.npy\n",
    "\n",
    "%ls tapnet/checkpoints"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "pip install --upgrade \"jax[cpu]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FxlHY242m-6Q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Imports {form-width: \"25%\"}\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "import tree\n",
    "\n",
    "from tapnet import tapir_model\n",
    "from tapnet.utils import transforms\n",
    "from tapnet.utils import viz_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7rfy2yobnHqw"
   },
   "outputs": [],
   "source": [
    "# @title Load Checkpoint {form-width: \"25%\"}\n",
    "\n",
    "checkpoint_path = 'tapnet/checkpoints/tapir_checkpoint.npy'\n",
    "ckpt_state = np.load(checkpoint_path, allow_pickle=True).item()\n",
    "params, state = ckpt_state['params'], ckpt_state['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "I7wOMJoSQzq1"
   },
   "outputs": [],
   "source": [
    "# @title Build Model {form-width: \"25%\"}\n",
    "\n",
    "def build_model(frames, query_points):\n",
    "  \"\"\"Compute point tracks and occlusions given frames and query points.\"\"\"\n",
    "  model = tapir_model.TAPIR()\n",
    "  outputs = model(\n",
    "      video=frames,\n",
    "      is_training=False,\n",
    "      query_points=query_points,\n",
    "      query_chunk_size=64,\n",
    "  )\n",
    "  return outputs\n",
    "\n",
    "model = hk.transform_with_state(build_model)\n",
    "model_apply = jax.jit(model.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ogRTRVgfSq0W"
   },
   "outputs": [],
   "source": [
    "# @title Utility Functions {form-width: \"25%\"}\n",
    "\n",
    "def preprocess_frames(frames):\n",
    "  \"\"\"Preprocess frames to model inputs.\n",
    "\n",
    "  Args:\n",
    "    frames: [num_frames, height, width, 3], [0, 255], np.uint8\n",
    "\n",
    "  Returns:\n",
    "    frames: [num_frames, height, width, 3], [-1, 1], np.float32\n",
    "  \"\"\"\n",
    "  frames = frames.astype(np.float32)\n",
    "  frames = frames / 255 * 2 - 1\n",
    "  return frames\n",
    "\n",
    "\n",
    "def postprocess_occlusions(occlusions, expected_dist):\n",
    "  \"\"\"Postprocess occlusions to boolean visible flag.\n",
    "\n",
    "  Args:\n",
    "    occlusions: [num_points, num_frames], [-inf, inf], np.float32\n",
    "    expected_dist: [num_points, num_frames], [-inf, inf], np.float32\n",
    "\n",
    "  Returns:\n",
    "    visibles: [num_points, num_frames], bool\n",
    "  \"\"\"\n",
    "  # visibles = occlusions < 0\n",
    "  visibles = (1 - jax.nn.sigmoid(occlusions)) * (1 - jax.nn.sigmoid(expected_dist)) > 0.5\n",
    "  return visibles\n",
    "\n",
    "def inference(frames, query_points):\n",
    "  \"\"\"Inference on one video.\n",
    "\n",
    "  Args:\n",
    "    frames: [num_frames, height, width, 3], [0, 255], np.uint8\n",
    "    query_points: [num_points, 3], [0, num_frames/height/width], [t, y, x]\n",
    "\n",
    "  Returns:\n",
    "    tracks: [num_points, 3], [-1, 1], [t, y, x]\n",
    "    visibles: [num_points, num_frames], bool\n",
    "  \"\"\"\n",
    "  # Preprocess video to match model inputs format\n",
    "  frames = preprocess_frames(frames)\n",
    "  num_frames, height, width = frames.shape[0:3]\n",
    "  query_points = query_points.astype(np.float32)\n",
    "  frames, query_points = frames[None], query_points[None]  # Add batch dimension\n",
    "\n",
    "  # Model inference\n",
    "  rng = jax.random.PRNGKey(42)\n",
    "  outputs, _ = model_apply(params, state, rng, frames, query_points)\n",
    "  outputs = tree.map_structure(lambda x: np.array(x[0]), outputs)\n",
    "  tracks, occlusions, expected_dist = outputs['tracks'], outputs['occlusion'], outputs['expected_dist']\n",
    "\n",
    "  # Binarize occlusions\n",
    "  visibles = postprocess_occlusions(occlusions, expected_dist)\n",
    "  return tracks, visibles\n",
    "\n",
    "\n",
    "def sample_random_points(frame_max_idx, height, width, num_points):\n",
    "  \"\"\"Sample random points with (time, height, width) order.\"\"\"\n",
    "  y = np.random.randint(0, height, (num_points, 1))\n",
    "  x = np.random.randint(0, width, (num_points, 1))\n",
    "  t = np.random.randint(0, frame_max_idx + 1, (num_points, 1))\n",
    "  points = np.concatenate((t, y, x), axis=-1).astype(np.int32)  # [num_points, 3]\n",
    "  return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fastplotlib as fpl\n",
    "from ipywidgets import IntSlider, VBox, Layout\n",
    "from sidecar import Sidecar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('/home/clewis7/Desktop/tapvid_davis/tapvid_davis.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_vids = [\n",
    "    \"paragliding-launch\", \"kite-surf\", \"drift-chicane\",\n",
    "    \"dance-twirl\", \"dog\", \"dogs-jump\",\n",
    "    \"car-roundabout\", \"soapbox\", \"breakdance\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CAITLIN SELECT VID HERE HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid_name = selected_vids[0]\n",
    "video_resized = data[vid_name][\"video\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787ab41265004d379cba93a009468db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RFBOutputContext()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = fpl.Plot(size=(700, 400))\n",
    "\n",
    "plot.add_image(video_resized[0])\n",
    "\n",
    "def update_frame(change):\n",
    "    ix = change[\"new\"]\n",
    "    plot.graphics[0].data = video_resized[ix]\n",
    "\n",
    "slider = IntSlider(min=0, max=video_resized.shape[0] - 1, step=1, value=0)\n",
    "slider.observe(update_frame, \"value\")\n",
    "slider.layout = Layout(width=\"700px\")\n",
    "\n",
    "with Sidecar(title=\"draw\"):\n",
    "    display(VBox([plot.show(), slider]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot.camera.world.scale_y *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw a polygon around the horse and rider by clicking on the polygon tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.draw import polygon2mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample random points within the polygon\n",
    "vertices = plot.selectors[0].get_vertices()\n",
    "\n",
    "# returns boolean mask\n",
    "mask = polygon2mask(video_resized.shape[1:-1], vertices).T\n",
    "\n",
    "# get points\n",
    "pts = np.argwhere(mask).astype(np.float32)\n",
    "\n",
    "# random sample of points\n",
    "n_query = 100\n",
    "ixs = np.random.choice(range(pts.shape[0]), n_query, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushalk/repos/fastplotlib/fastplotlib/graphics/_features/_base.py:34: UserWarning: converting float64 array to float32\n",
      "  warn(f\"converting {array.dtype} array to float32\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7fb468106d90 to ScatterGraphic at 0x7fb468137950>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot.add_scatter(np.fliplr(pts[ixs]), sizes=10, colors=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rIASK5A2Rj0X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: output size is not a multiple of 8. Final layer will round size down.\n"
     ]
    }
   ],
   "source": [
    "query_points = np.column_stack([np.zeros(n_query), pts[ixs]]).astype(np.int32)\n",
    "tracks, visibles = inference(video_resized, query_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6554250bc52a49c5b4064e1363725fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RFBOutputContext()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tracks = fpl.Plot(size=(700, 400))\n",
    "\n",
    "plot_tracks.add_image(video_resized[0])\n",
    "\n",
    "pos0 = np.vstack([tracks[i][0] for i in range(len(tracks))])\n",
    "\n",
    "plot_tracks.add_scatter(\n",
    "    pos0, \n",
    "    cmap=\"jet\",\n",
    "    sizes=5, \n",
    "    name=\"pts\"\n",
    ")\n",
    "\n",
    "def update_frame(change):\n",
    "    frame_ix = change[\"new\"]\n",
    "    plot_tracks.graphics[0].data = video_resized[frame_ix]\n",
    "    \n",
    "    for i in range(len(tracks)):\n",
    "        plot_tracks[\"pts\"].data[i] = tracks[i][frame_ix]\n",
    "\n",
    "slider = IntSlider(min=0, max=video_resized.shape[0] - 1, step=1, value=0)\n",
    "slider.observe(update_frame, \"value\")\n",
    "slider.layout = Layout(width=\"700px\")\n",
    "\n",
    "with Sidecar(title=\"tracks\"):\n",
    "    display(VBox([plot_tracks.show(), slider]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_tracks.camera.world.scale_y *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a gaussian filer to smooth the tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tracks_filt = list()\n",
    "for t in tracks:\n",
    "    # gaussian filter xs and ys\n",
    "    tracks_filt.append(\n",
    "        np.column_stack(\n",
    "            [\n",
    "                gaussian_filter1d(t[:, 0], 1.5), # filter x vals\n",
    "                gaussian_filter1d(t[:, 1], 1.5)  # filter y vals\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_tracks.add_line_collection(\n",
    "    tracks_filt, \n",
    "    cmap=\"jet\", # same cmap, colors will match\n",
    "    thickness=2,\n",
    "    name=\"tracks\"\n",
    ")\n",
    "\n",
    "# bring our points up so they're more visible\n",
    "plot_tracks[\"pts\"].position_z = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 2, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_array = np.dstack(tracks_filt)\n",
    "tracks_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shpae is `[n_frames, 2-xy, n_points]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_tracks[\"tracks\"][:].cmap = \"winter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"./tracks/{vid_name}.npy\", tracks_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 64K\n",
      "-rw-r--r-- 1 kushalk 63K Jul 12 03:56 paragliding-launch.npy\n"
     ]
    }
   ],
   "source": [
    "ll -h ./tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "last_runtime": {
    "build_target": "//learning/grp/tools/ml_python:ml_notebook",
    "kind": "private"
   },
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
